STEP BY STEP INSTRUCTION TO COMPLETE THE PROJECT
=====================================================================

Step1:

Fork the repository:

https://github.com/Sonal0409/DevOps-Capstone-Project.git

The above repository contains source code and test cases of a spring boot project
==========================================================================

Step 2: We will write github actions workflow YAML file to Build the code using Maven

Execute below  steps:

 > In the repository -> click on Actions Tab --> Choose a Workflow --> Setup and workflow yourself

 > A new Yaml file will open--> give name as ContinousIntegration.yml

 > Add the below YAML code


name: CI Workflow for Build
on:
  push:
jobs:
  endproject:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - name: Set up JDK 11
        uses: actions/setup-java@v3
        with:
          java-version: '11'
          distribution: 'temurin'
          cache: maven
      - name: Build with Maven
        run: mvn -B package --file pom.xml


=======================================================================

Step 3: We will now create a dockerfile and then build image using github actions. 
        We will also push the image to dockerhub using github Actions

Execute below  steps:

 > In the repository create a new file with name as Dockerfile

Add the below lines in the dockerfile and save the file


FROM tomcat:8
COPY target/java-example.war /usr/local/tomcat/webapps/ROOT.war
EXPOSE 8080
CMD ["catalina.sh", "run"]


Save the file

> As we have to push the image to dockerhub, we will create secrets in the repository to save dockerhub username and dockerhub password

> For this go to Settings tab of repository > go to secrets and variables > click on to Actions > Secrets Tab > Repository secrets > click on new repository secret

	> give name as DOCKERHUB_USERNAME ==> Secret as > your dockerhub username > Click on Add secret

	> Again  click on new repository secret > give name as DOCKERHUB_TOKEN > Secret as > your dockerhub password> click on add secret

	> Give the secret names in UPPERCASE, as we use the same secret name in the actions YAML file.

> In the repository > now go to .github/workflow folder --> you will find the ContinousIntegration.yml file

> Click on Edit the file 

> Replace the content of the file with below content. 


name: CI Workflow for Docker Build
on:
  push:
jobs:
  endproject:
    env:
     appName: "docker-image"
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      - name: Set up JDK 11
        uses: actions/setup-java@v3
        with:
          java-version: '11'
          distribution: 'temurin'
          cache: maven
      - name: Build with Maven
        run: mvn -B package --file pom.xml
      - name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      - name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.appName }}:latest


Save the file

 > In the above YAMl we have added the steps
       > to build dockerfile into an image
       > Push the Image to dockerhub

> Now the workflow will run successfully
 	> It will build code using maven 
        > Dockerfile will be built into an Image
        > docker image will be sent to dockerhub.

> validate all the above.

========================================================

Step 4: Create kubernetes Helm chart to deploy above image and push charts to github repo

> Connect to devOps lab > here we will install helm 

Execute below commands:

# curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get-helm-3 > get_helm.sh
# chmod 700 get_helm.sh
# ./get_helm.sh


> clone the github repo in which we have to push the charts

# git clone https://github.com/Sonal0409/DevOps-Capstone-Project.git
# ls
# cd DevOps-Capstone-Project

> Now we have to create a new Helm chart using which we are going to deploy our Custom Docker image. Follow below commands to create a new helm Chart

# helm create webapp
# ls -al webapp

> By default, you will get a lot of files inside this helm chart but we are going to delete those so that we donâ€™t see error while deploying these.

# cd webapp/
# pwd
# cd templates/
# ls -al
# rm -rf *.yaml NOTES.txt tests ../values.yaml 
# ls -la

> Create deployment.yaml inside templates directory with below content

apiVersion: apps/v1

kind: Deployment

metadata:

  name: ais-ifm

  labels:

    app: ais

spec:

  replicas: 3

  selector:

    matchLabels:
      app: ais
      tier: web

  template:

    metadata:

      labels:
       app: ais
       tier: web

    spec:

      containers:

      - name: ais

        image: edu123/docker-image

        ports:

        - containerPort: 8090

        resources:

          limits:

            cpu: 1000m

            memory: 600Mi

          requests:

            cpu: 500m

            memory: 300Mi




Create a service YAMl
=======================

vim service.yml

---

apiVersion: v1

kind: Service

metadata:

 name: mysvc

spec:

 type: NodePort

 ports:

  - targetPort: 8080

    port: 8080

 selector:
  app: ais


[OPTIONAL]
You can check if your chart is correct or not

# cd ../..

root@ip-172-31-38-52:~/DevOps-Capstone-Project# helm install mydemo webapp


> we will also push the helm charts folder to the git hub repo

come out of templates and webapp folder

> cd ../..

> you will be in the repo folder

Execute git commands to commit the webapp folder and push to github

# git add .
# git commit -m "done helm"
# git push origin master
username: 
password: personal access token

=============================================
Step 5: Using terraform to create infrastructure - Ec2 instance where we will install kubernetes and docker.

> Go to devops Lab

> create a terraform file 

# vim kubernetes.tf

and add below code:


variable "aws_region" {
        default = "us-east-1"
}

variable "vpc_cidr" {
        default = "10.20.0.0/16"
}

variable "subnets_cidr" {
        default = "10.20.1.0/24"
}

variable "azs" {
        default = "us-east-1a"
}


provider "aws" {
        region = var.aws_region  
       access_key = "AKIAUJU24ZR3T7G3YHHH"

       secret_key = "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"

	
}


# VPC
resource "aws_vpc" "terra_vpc" {
  cidr_block       = var.vpc_cidr
  tags = {
    Name = "TerraVPC"
  }
}

# Internet Gateway
resource "aws_internet_gateway" "terra_igw" {
  vpc_id = aws_vpc.terra_vpc.id
  tags = {
    Name = "main"
  }
}

# Subnets : public
resource "aws_subnet" "public" {
  vpc_id = aws_vpc.terra_vpc.id
  cidr_block = var.subnets_cidr
  availability_zone = var.azs
  map_public_ip_on_launch = true
  tags = {
    Name = "Subnet"
  }
}

# Route table: attach Internet Gateway 
resource "aws_route_table" "public_rt" {
  vpc_id = aws_vpc.terra_vpc.id
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.terra_igw.id
  }
  tags = {
    Name = "publicRouteTable"
  }
}

# Route table association with public subnets
resource "aws_route_table_association" "a" {
  subnet_id      = aws_subnet.public.id
  route_table_id = aws_route_table.public_rt.id
}


resource "aws_security_group" "my_security_group" {
  name = "mysg"
  description = "my security group."
  vpc_id = aws_vpc.terra_vpc.id
}

resource "aws_security_group_rule" "ssh_ingress_access" {
  type = "ingress"
  from_port = 22
  to_port = 22
  protocol = "tcp"
  cidr_blocks = [ "0.0.0.0/0" ] 
  security_group_id = "${aws_security_group.my_security_group.id}"
}

resource "aws_security_group_rule" "egress_access" {
  type = "egress"
  from_port = 0
  to_port = 65535
  protocol = "tcp"
  cidr_blocks = [ "0.0.0.0/0" ]
  security_group_id = "${aws_security_group.my_security_group.id}"
}

data "aws_ami" "latest-ubuntu" {
most_recent = true

  filter {
      name   = "name"
      values = ["ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-20230517"]
  }

  filter {
      name   = "virtualization-type"
      values = ["hvm"]
  }
}


resource "aws_launch_configuration" "aws_autoscale_conf" {
  name          = "web_config"
  image_id      = "${data.aws_ami.latest-ubuntu.id}"
  instance_type = "t2.micro"
  security_groups =  [ "${aws_security_group.my_security_group.id}" ]
}


resource "aws_autoscaling_group" "mygroup" {
#  availability_zones        =  ["${var.azs}"]
  name                      = "autoscalegroup"
  max_size                  = 1
  min_size                  = 1
  health_check_grace_period = 30
  health_check_type         = "EC2"
 force_delete              = true
  vpc_zone_identifier       = ["${aws_subnet.public.id}"]
  termination_policies      = ["OldestInstance"]
  launch_configuration      = aws_launch_configuration.aws_autoscale_conf.name
}


Save the file (:wq!)

run below commands:

# terraform init
# terraform apply

give: yes
======================================
Step 6: Go to AWS lab and connect to the instance

> install kubernetes on the Ec2 instance

# sudo su -


# apt-get update && apt-get install -y curl apt-transport-https
# sudo mkdir -p /etc/apt/keyrings
# curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
# echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
# sudo apt-get update
# sudo apt-get install -y containerd.io docker-ce

# curl -s https://packages.cloud.google.com/apt/doc/yum-key.gpg | apt-key add -
# echo "deb http://apt.kubernetes.io/ kubernetes-xenial main" >/etc/apt/sources.list.d/kubernetes.list
# apt-get update
# apt -y install kubeadm kubectl kubelet


> Execute below set of commands to Initialize Kubernetes Cluster:

sed -i 's|disabled_plugin|#disabled_plugin|g' /etc/containerd/config.toml 
service containerd restart
kubeadm init --ignore-preflight-errors=all


> Once Kubernetes Cluster is initialized you can proceed with below commands:

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml

kubectl taint nodes --all node-role.kubernetes.io/control-plane-

kubectl get nodes


> We also need to install Helm utility using below set of commands:


curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get-helm-3 > get_helm.sh
chmod 700 get_helm.sh
./get_helm.sh

> Now we have to enable root password and root user authentication to proceed with SSH connectivity from GitHub actions pipeline. 


sed -i 's|PasswordAuthentication no|PasswordAuthentication yes|g' /etc/ssh/sshd_config
sed -i 's|#PermitRootLogin prohibit-password|PermitRootLogin yes|g' /etc/ssh/sshd_config
service sshd restart
passwd root
ssh root@localhost "date"		(Enter Root user password configured by you in previous command)


===============================================

Step 7: Integrating Deploy stage to GitHub actions for performing deployment of containers on Kubernetes.

> Once Kubernetes Cluster setup is completed, we need to configure deploy stage to deploy helm chart.

> For this go to Settings tab of repository > go to secrets and variables > click on to Actions > Secrets Tab > Repository secrets > click on new repository secret

	> give name as HOST  ==> Secret as > your ec2 instance public ip > Click on Add secret

	> Again  click on new repository secret > give name as USERNAME  > Secret as > root > click on add secret

	> Again  click on new repository secret > give name as PASSWORD  > Secret as > root > click on add secret
	
	>  Again  click on new repository secret > give name as PORT  > Secret as > 22 > click on add secret

	> Give the secret names in UPPERCASE, as we use the same secret name in the actions YAML file.

> In the repository > now go to .github/workflow folder --> you will find the ContinousIntegration.yml file

> Click on Edit the file 

> Replace the content of the file with below content. 

name: CI Workflow for Docker Build

on:
  push:

jobs:
  docker:
    env:
     appName: "docker-image"
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      - name: Set up JDK 11
        uses: actions/setup-java@v3
        with:
          java-version: '11'
          distribution: 'temurin'
          cache: maven
      - name: Build with Maven
        run: mvn -B package --file pom.xml
      - name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      - name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.appName }}:latest
      - name: Executing Kubectl command on Kubernetes Server Remotely
        uses: appleboy/ssh-action@v0.1.10
        with:
         host: ${{ secrets.HOST }}
         username: ${{ secrets.USERNAME }}
         password: ${{ secrets.PASSWORD }}
         port: ${{ secrets.PORT }}
         script: |
           git clone https://github.com/Sonal0409/DevOps-Capstone-Project.git
           cd MavenBuild-SL
           helm list -A
           helm install mavenbuild-dev ./webapp
           helm list -A
           kubectl get all


















































































